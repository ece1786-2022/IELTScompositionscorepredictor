{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1xB6jN0Vvqu_fy46UncRCB-DCDFJ5ND45","authorship_tag":"ABX9TyMbF1BL28tbIqotO2gEHM+Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"231613f26a6a4bb385a4642aa8ec4131":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_479bbf8d4cf142f48278de536055f9e0","IPY_MODEL_1817f2e2194a41deb7e7a9f4c3743b09","IPY_MODEL_d7cc988b7564480fbcd1ca9b116bda6e"],"layout":"IPY_MODEL_1262ed6c99a64780821ced2ed39e2f83"}},"479bbf8d4cf142f48278de536055f9e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a273c9b9bd04d01950c95b38422e21f","placeholder":"​","style":"IPY_MODEL_7fc9b1beaf16426f8de4d8a61f4dce2b","value":"100%"}},"1817f2e2194a41deb7e7a9f4c3743b09":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_19c29a58c7304d73bfcbfcc94a2ee7d0","max":20826,"min":0,"orientation":"horizontal","style":"IPY_MODEL_259e7677f4a4497d949841d6b4d1cfb7","value":20826}},"d7cc988b7564480fbcd1ca9b116bda6e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc4ef90249464095a93065366d9cb537","placeholder":"​","style":"IPY_MODEL_1cae406aa27349549419efa6a4b6f784","value":" 20826/20826 [4:50:28&lt;00:00,  1.38it/s]"}},"1262ed6c99a64780821ced2ed39e2f83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a273c9b9bd04d01950c95b38422e21f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fc9b1beaf16426f8de4d8a61f4dce2b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"19c29a58c7304d73bfcbfcc94a2ee7d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"259e7677f4a4497d949841d6b4d1cfb7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bc4ef90249464095a93065366d9cb537":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cae406aa27349549419efa6a4b6f784":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d603d258f29745908bd94fa0b49bc9d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5f98c9b83261418ab9793a285f65eecb","IPY_MODEL_79633e39591c47d6a6054d59092a4b1c","IPY_MODEL_61139fa76bd14c1ebe264a44aec281ef"],"layout":"IPY_MODEL_3e03cdd5ba30452ba3960368e93c2612"}},"5f98c9b83261418ab9793a285f65eecb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22f8ab7b5ba142fc9c5da057a45b7acd","placeholder":"​","style":"IPY_MODEL_5a38c1ff173342f687686efbff742e44","value":"Downloading builder script: 100%"}},"79633e39591c47d6a6054d59092a4b1c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_015b8cb0df344fef82ff180ef8ba5f68","max":4203,"min":0,"orientation":"horizontal","style":"IPY_MODEL_30c0a8774e064359ba79e114dbd8aac8","value":4203}},"61139fa76bd14c1ebe264a44aec281ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e29050943d745ca906573c6ed8412f6","placeholder":"​","style":"IPY_MODEL_8ca39237b49442a59f4862d94589bb1e","value":" 4.20k/4.20k [00:00&lt;00:00, 124kB/s]"}},"3e03cdd5ba30452ba3960368e93c2612":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22f8ab7b5ba142fc9c5da057a45b7acd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a38c1ff173342f687686efbff742e44":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"015b8cb0df344fef82ff180ef8ba5f68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30c0a8774e064359ba79e114dbd8aac8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e29050943d745ca906573c6ed8412f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ca39237b49442a59f4862d94589bb1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZCEST3y0Ew3","executionInfo":{"status":"ok","timestamp":1670181354746,"user_tz":300,"elapsed":15032,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}},"outputId":"efdb525d-b233-4f9f-99b4-3f8e8c268c99"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.25.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.7/dist-packages (0.3.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.11.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from evaluate) (21.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from evaluate) (3.1.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from evaluate) (4.13.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from evaluate) (1.21.6)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.70.14)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from evaluate) (4.64.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2.23.0)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2022.11.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.3.6)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2.7.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from evaluate) (1.3.5)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.13.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->evaluate) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (1.25.11)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->evaluate) (3.10.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->evaluate) (2022.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n"]}],"source":["!pip install transformers\n","!pip install evaluate"]},{"cell_type":"code","source":["import csv\n","import torch\n","from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n","\n","topics = []\n","contents = []\n","labels = []\n","\n","with open('/content/drive/MyDrive/ECE1786/project/IEL.csv', newline='') as csvfile:\n","    spamreader = csv.reader(csvfile)\n","    for i, row in enumerate(spamreader):\n","        if i != 0:\n","          topics.append(row[0])\n","          contents.append(row[1])\n","          labels.append(row[2])\n","\n","\n","print(len(topics))\n","print(len(contents))\n","print(len(labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JNZDtLAK0HXg","executionInfo":{"status":"ok","timestamp":1670181524781,"user_tz":300,"elapsed":502,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}},"outputId":"de7bc7bc-7097-408e-9bd2-109d73e63c03"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["4004\n","4004\n","4004\n"]}]},{"cell_type":"code","source":["classes = {\n","    '<4': 0,\n","    '4.0': 1,\n","    '4.5': 2,\n","    '5.0': 3,\n","    '5.5': 4,\n","    '6.0': 5,\n","    '6.5': 6,\n","    '7.0': 7,\n","    '7.5': 8,\n","    '8.0': 9,\n","    '8.5': 10,\n","    '9.0': 11\n","}\n","\n","labels2scores = {\n","    '0': 3.5,\n","    '1': 4,\n","    '2': 4.5,\n","    '3': 5,\n","    '4': 5.5,\n","    '5': 6,\n","    '6': 6.5,\n","    '7': 7,\n","    '8': 7.5,\n","    '9': 8,\n","    '10': 8.5,\n","    '11': 9\n","}\n","\n","from transformers import GPT2Tokenizer\n","\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n","\n","tokenizer.pad_token = tokenizer.eos_token\n","class GPT2Dataset(Dataset):\n","\n","  def __init__(self, topics, contents, labels, tokenizer, max_length=512):\n","\n","    self.tokenizer = tokenizer\n","    self.input_ids = []\n","    self.attn_masks = []\n","    self.labels = []\n","    self.last_idx = []\n","    self.targets = []\n","\n","    for i in range(len(topics)):\n","      input = topics[i].strip() + \" \" + contents[i].strip()\n","      encodings_dict = self.tokenizer(input, truncation=True, max_length=max_length, padding=\"max_length\")\n","      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n","      if labels[i] != \"<4\":\n","        label = classes[str(float(labels[i]))]\n","        self.labels.append(label)\n","        self.targets.append(labels2scores[str(label)])\n","      else:\n","        label = classes[labels[i]]\n","        self.labels.append(label)\n","        self.targets.append(labels2scores[str(label)])\n","      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n","\n","      eot_idx = len(encodings_dict['input_ids']) - 1\n","      for j, id in enumerate(encodings_dict['input_ids']):\n","        if id == self.tokenizer.encode(\"<|endoftext|>\")[0]:\n","          eot_idx = j - 1\n","          break\n","      self.last_idx.append(j-1)\n","      \n","    print(len(self.last_idx))\n","    print(len(self.labels))\n","  def __len__(self):\n","    return len(self.input_ids)\n","\n","  def __getitem__(self, idx):\n","\n","    return self.input_ids[idx], self.attn_masks[idx], self.labels[idx], self.targets[idx], self.last_idx[idx]\n","batch_size = 2\n","dataset = GPT2Dataset(topics, contents, labels, tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kpj6CDQM0JdH","executionInfo":{"status":"ok","timestamp":1670181639603,"user_tz":300,"elapsed":114034,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}},"outputId":"828f29e3-8afa-42aa-cdcf-846d0b241cee"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["4004\n","4004\n"]}]},{"cell_type":"code","source":["train_size = int(0.8 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","torch.manual_seed(0)\n","\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","train_dataloader = DataLoader(\n","            train_dataset,\n","            sampler = RandomSampler(train_dataset),\n","            batch_size = batch_size\n","        )\n","\n","validation_dataloader = DataLoader(\n","            val_dataset,\n","            sampler = SequentialSampler(val_dataset),\n","            batch_size = batch_size\n","        )\n","\n","## make sure \n","print(torch.sum(train_dataset[0][0]))\n","\n","print(train_dataset[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kBe2K7vl0icw","executionInfo":{"status":"ok","timestamp":1670181639605,"user_tz":300,"elapsed":27,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}},"outputId":"825c8488-7ed3-445e-9198-2b949fc0997d"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(5779971)\n","(tensor([ 4366,   661,  1975,   326,   645,   530,   815,   307,  3142,   284,\n","         2555,  1762,   706,   262,  2479,   286,  6135,    13,   220,   198,\n","         4864,    11,  1854,   910,   612,  6584,   470,   307,   257, 17385,\n","          319,  2479,   290,  2687,   815,   307,  3142,   284,   670,  7692,\n","          286,   511,  2479,    13,   220,   198, 48873,  1111,  5009,    11,\n","         1577,   534,   898,  4459,   290,  2291,  5981,  6096,    13,  4380,\n","          743,  2328,   326,  2479,   318,   257,  1994,  3210,   284, 22232,\n","         1762, 40460,    13,   220,  6430,   422,   616,  6650,    11,   314,\n","         1975,   326,  2479,   815,   407,   307,   257, 17385,   329,   530,\n","          284,  1620,    13,   201,   198,   201,   198,  2949,  2300,   703,\n","         1468,   262,   661,   389,    11,   484,   991,   460,  8676,  2405,\n","           13,  7129,   815,   407,   307,   262,  2318,   284, 16222,  1586,\n","          262, 13830,  1762, 16826,    13,  1114,  1672,    11,  1011,   262,\n","         4283,  4896,  2214,    11,   262,  4697,   661,   588, 33872,   347,\n","         2001,   316,    11,   508,   318,  1541,  9722,  4101,    11,   991,\n","         1100,  5079,  3136,  4445,   290,  4654,  1123,  2496,  2706,  4495,\n","           13,  1119, 14245,  1975,    11,   706,  1719, 24169,  1998,    11,\n","          511, 42806,   286,   262,  1910,   290,  5370,   389,   517, 15345,\n","          290,  7187,   621,   262,  1862,   661,    13, 23730,    11,   340,\n","          318, 24673,   220,   284,  3958,   220,  4697,   661,   422,  1762,\n","         6974,   780,   286,  2479,   284,  5052,   511,  2854,    13,   201,\n","          198,   201,   198,  2782, 43011,    11,   617,   286,   262,  1762,\n","         4433,  1029,  3518,  3403,   543,   318,   407,  1774,   329,   220,\n","         4697,   661,    13,  1114,  1672,    11,   287,   262,  5701,  2214,\n","           11,  2479,  6870,   530,   872,    88,   271,   605, 17385,   543,\n","         1724,   262,  1767,   338,  3450, 17385,   481, 10070,   511,  4045,\n","         2854,   287,   262,  5449,    13,  4900,    11,   661,  1826,   262,\n","         4096,  2479,   484,  4327,   284,  8058,    11,   220,   484,   991,\n","          481,   220,   307,   257,  3985,   284,  8676,  2405,    13,  7214,\n","        14119,   355,   281,  1672,    11,   257,   582,   460,   991,   307,\n","          257,  3985,   287,  1524,   618,   465,  2479,   318,   625,  6135,\n","           13, 16227,    11,   356,   460,  6189,   220,   766,   326,  2479,\n","         1244,   307,  1611,   286, 17385,   284,   423,   281,  2928,   319,\n","          511,   670,   475,   340,   857,   407,  1265,   606,   284,  6871,\n","         1762,   287,   262,   886,    13,   220,   201,   198,   201,   198,\n","          818,  4506,    11,  2479,   318,   655,   262,  4096,  3210,   284,\n","         8106,   262,   530,   318,  4197,   329,   257,  2176,  2292,   393,\n","          407,   475,   340,   815,   407,   307,   262,  6737,   284,  5052,\n","         1771,   530,   460,   670,   393,   407,    13,  1400,  2300,   287,\n","          262,  4283,  1910,   393,  5701,  2214,    11,   883,  7713,   393,\n","         1938,  3863,   389,  1468,   475,   484,   991,   460,  2222,   511,\n","         1998,   284,   262,  1306,  5270,   287,  3294,  2842,    13, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","        50256, 50256]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0]), 3, 5, 418)\n"]}]},{"cell_type":"code","source":["class GPT2_with_regressor(torch.nn.Module):\n","  def __init__(self, embd_size):\n","    super(GPT2_with_regressor, self).__init__()\n","    self.encoder = GPT2Model.from_pretrained(\"gpt2-medium\")\n","    self.regressor = torch.nn.Linear(embd_size, 1)\n","\n","  def forward(self, input, last_idxes):\n","    outputs = self.encoder(**input).last_hidden_state\n","    hidden_states = []\n","    for i in range(len(last_idxes)):\n","      hidden_states.append(outputs[i, last_idxes[i], :][None, :])\n","    hidden_states = torch.cat(hidden_states, dim=0)\n","    outputs = self.regressor(hidden_states)\n","    return outputs\n"],"metadata":{"id":"7jNNWtaIwTNj","executionInfo":{"status":"ok","timestamp":1670181639605,"user_tz":300,"elapsed":21,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["from transformers import GPT2Model\n","torch.manual_seed(0)\n","\n","import torch\n","model = GPT2_with_regressor(1024)\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","model.to(device)\n","# regressor.to(device)\n","\n","from torch.optim import AdamW\n","\n","optimizer = AdamW(model.parameters(), lr=1e-5)\n","\n","from transformers import get_scheduler\n","\n","num_epochs = 13\n","num_training_steps = num_epochs * len(train_dataloader)\n","lr_scheduler = get_scheduler(\n","    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",")"],"metadata":{"id":"hvx-2l-O0nrd","executionInfo":{"status":"ok","timestamp":1670181650373,"user_tz":300,"elapsed":10789,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["print(model)"],"metadata":{"id":"NqR7_3_Xwhw0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scores = torch.tensor([3.5, 4, 4.5, 5, 5.5, 6, 6.5, 7, 7.5, 8, 8.5, 9])\n","scores = scores.to(device)"],"metadata":{"id":"_WORlErE8s37","executionInfo":{"status":"ok","timestamp":1670181650374,"user_tz":300,"elapsed":13,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def custom_activation(inputs):\n","  inputs[inputs<3.5] = 3.5\n","  inputs[inputs>9] = 9\n","  return inputs"],"metadata":{"id":"WHbHJa-rmqAq","executionInfo":{"status":"ok","timestamp":1670181650374,"user_tz":300,"elapsed":12,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(0)\n","from tqdm.auto import tqdm\n","import evaluate\n","progress_bar = tqdm(range(num_training_steps))\n","\n","model.encoder.config.pad_token_id = tokenizer.pad_token_id\n","\n","mse = torch.nn.MSELoss()\n","val_distance = []\n","for epoch in range(num_epochs):\n","    model.train()\n","    \n","    total = 0\n","    distance = 0\n","    # metric = evaluate.load(\"accuracy\")\n","    for input, attn_masks, labels, targets, last_idxes in train_dataloader:\n","        x = {\n","             \"input_ids\": input,\n","             \"attention_mask\": attn_masks,\n","        }\n","        \n","        batch = {k: v.to(device) for k, v in x.items()}\n","        outputs = model(batch, last_idxes)\n","        # outputs = torch.special.expit(outputs).squeeze()\n","        outputs = custom_activation(outputs).squeeze()\n","        predictions = []\n","        if len(outputs.size()) == 0:\n","          pred_idx = torch.argmin(abs(scores - outputs))\n","          predictions.append(pred_idx)\n","        else:\n","          for i in range(outputs.size(0)):\n","            pred_idx = torch.argmin(abs(scores - outputs[i]))\n","            predictions.append(pred_idx)\n","          \n","        predictions = torch.tensor(predictions)\n","\n","        for j in range(len(predictions)):\n","          distance += abs(scores[predictions[j]] - scores[labels[j]])\n","        total += len(predictions)\n","\n","\n","        targets = targets.to(device)\n","        loss = mse(outputs.float(), targets.float())\n","        loss.backward()\n","        optimizer.step()\n","        lr_scheduler.step()\n","        optimizer.zero_grad()\n","        progress_bar.update(1)\n","    distance = distance / total\n","    print(distance)\n","    val_distance.append(distance)\n","    # train_acc = metric.compute()['accuracy']\n","    # print(train_acc)\n","    # break\n","    # train_accs.append(train_acc)\n","    \n","    # print(\"Epoch: {}, Train acc: {}\".format(epoch + 1, train_acc))\n","    torch.save(model.state_dict(), \"/content/drive/MyDrive/ECE1786/project/gpt2_regression_{}.pt\".format(epoch))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337,"referenced_widgets":["231613f26a6a4bb385a4642aa8ec4131","479bbf8d4cf142f48278de536055f9e0","1817f2e2194a41deb7e7a9f4c3743b09","d7cc988b7564480fbcd1ca9b116bda6e","1262ed6c99a64780821ced2ed39e2f83","3a273c9b9bd04d01950c95b38422e21f","7fc9b1beaf16426f8de4d8a61f4dce2b","19c29a58c7304d73bfcbfcc94a2ee7d0","259e7677f4a4497d949841d6b4d1cfb7","bc4ef90249464095a93065366d9cb537","1cae406aa27349549419efa6a4b6f784"]},"id":"YkYLT9Hb374G","executionInfo":{"status":"ok","timestamp":1670135604985,"user_tz":300,"elapsed":9199055,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}},"outputId":"21b0f547-9584-4a5f-b3b8-22ab26aa803a"},"execution_count":9,"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"231613f26a6a4bb385a4642aa8ec4131","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20826 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["tensor(1.4451, device='cuda:0')\n","tensor(0.8870, device='cuda:0')\n","tensor(0.7053, device='cuda:0')\n","tensor(0.5537, device='cuda:0')\n","tensor(0.4555, device='cuda:0')\n","tensor(0.3881, device='cuda:0')\n","tensor(0.3333, device='cuda:0')\n","tensor(0.2833, device='cuda:0')\n","tensor(0.2573, device='cuda:0')\n","tensor(0.2370, device='cuda:0')\n","tensor(0.2134, device='cuda:0')\n","tensor(0.1919, device='cuda:0')\n","tensor(0.1817, device='cuda:0')\n"]}]},{"cell_type":"code","source":["len(torch.tensor(3).size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T4FQ5GS5Foua","executionInfo":{"status":"ok","timestamp":1670022355321,"user_tz":300,"elapsed":297,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}},"outputId":"f81ad4d0-4721-4ff4-e89c-d442ed35909a"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["import evaluate\n","val_distance = []\n","for i in range(13):\n","  model.load_state_dict(torch.load(\"/content/drive/MyDrive/ECE1786/project/gpt2_regression_{}.pt\".format(i)))\n","\n","  model.eval()\n","  metric = evaluate.load(\"accuracy\")\n","  model.encoder.config.pad_token_id = tokenizer.pad_token_id\n","\n","  total = 0\n","  distance = 0\n","  for input, attn_masks, labels, targets, last_idxes in validation_dataloader:\n","      x = {\n","             \"input_ids\": input,\n","             \"attention_mask\": attn_masks,\n","      }\n","      batch = {k: v.to(device) for k, v in x.items()}\n","      outputs = model(batch, last_idxes)\n","\n","      outputs = custom_activation(outputs).squeeze()\n","      predictions = []\n","      if len(outputs.size()) == 0:\n","          pred_idx = torch.argmin(abs(scores - outputs))\n","          predictions.append(pred_idx)\n","      else:\n","          for i in range(outputs.size(0)):\n","            pred_idx = torch.argmin(abs(scores - outputs[i]))\n","            predictions.append(pred_idx)\n","\n","      predictions = torch.tensor(predictions)\n","      metric.add_batch(predictions=predictions, references=labels)\n","      for j in range(len(predictions)):\n","        distance += abs(scores[predictions[j]] - scores[labels[j]])\n","      total += len(predictions)\n","  distance = distance / total\n","  val_acc = metric.compute()['accuracy']\n","  print(distance, val_acc)\n","  val_distance.append(distance)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281,"referenced_widgets":["d603d258f29745908bd94fa0b49bc9d6","5f98c9b83261418ab9793a285f65eecb","79633e39591c47d6a6054d59092a4b1c","61139fa76bd14c1ebe264a44aec281ef","3e03cdd5ba30452ba3960368e93c2612","22f8ab7b5ba142fc9c5da057a45b7acd","5a38c1ff173342f687686efbff742e44","015b8cb0df344fef82ff180ef8ba5f68","30c0a8774e064359ba79e114dbd8aac8","6e29050943d745ca906573c6ed8412f6","8ca39237b49442a59f4862d94589bb1e"]},"id":"JCbWW2M9MtUF","executionInfo":{"status":"ok","timestamp":1670183032553,"user_tz":300,"elapsed":1382192,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}},"outputId":"245ad173-a659-41a1-d19c-97f779ee51ac"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d603d258f29745908bd94fa0b49bc9d6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["tensor(0.9176, device='cuda:0') 0.18851435705368288\n","tensor(0.8383, device='cuda:0') 0.1972534332084894\n","tensor(0.7709, device='cuda:0') 0.2571785268414482\n","tensor(0.7122, device='cuda:0') 0.29213483146067415\n","tensor(0.7097, device='cuda:0') 0.28963795255930086\n","tensor(0.6841, device='cuda:0') 0.3083645443196005\n","tensor(0.6885, device='cuda:0') 0.3096129837702871\n","tensor(0.6610, device='cuda:0') 0.3146067415730337\n","tensor(0.6523, device='cuda:0') 0.32209737827715357\n","tensor(0.6798, device='cuda:0') 0.299625468164794\n","tensor(0.6461, device='cuda:0') 0.3196004993757803\n","tensor(0.6511, device='cuda:0') 0.31585518102372034\n","tensor(0.6504, device='cuda:0') 0.3121098626716604\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"x6OomOK0MtTU"},"execution_count":null,"outputs":[]}]}