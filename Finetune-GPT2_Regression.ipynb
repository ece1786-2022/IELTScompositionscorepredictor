{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1xB6jN0Vvqu_fy46UncRCB-DCDFJ5ND45","authorship_tag":"ABX9TyO3mBCeObg5zKB/7Vi9yAQ+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"f4a1129d315d4798883a84333a7ca073":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc7a51b2a0d04e28b9ffab77b5de3cba","IPY_MODEL_837e6994b60a4befaa7305e1aed1a182","IPY_MODEL_c2c45ecf2f664c0689b61472a4229c3a"],"layout":"IPY_MODEL_376ba6fb32584bc082770b51a6a55029"}},"dc7a51b2a0d04e28b9ffab77b5de3cba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d08dbcc808e4820aee1eeac5a58ea54","placeholder":"​","style":"IPY_MODEL_4ea852587e2b43bd96efb88c80adb66f","value":" 83%"}},"837e6994b60a4befaa7305e1aed1a182":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a5c88a6018245c59064c210d4cd548e","max":20826,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1277473ba57245c49b598cf7a7c96b91","value":17274}},"c2c45ecf2f664c0689b61472a4229c3a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4385e7702ff547c59fab9b82deb5c34e","placeholder":"​","style":"IPY_MODEL_453cca8aeab84743ac8132468b3d6102","value":" 17274/20826 [3:55:33&lt;48:01,  1.23it/s]"}},"376ba6fb32584bc082770b51a6a55029":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d08dbcc808e4820aee1eeac5a58ea54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ea852587e2b43bd96efb88c80adb66f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a5c88a6018245c59064c210d4cd548e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1277473ba57245c49b598cf7a7c96b91":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4385e7702ff547c59fab9b82deb5c34e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"453cca8aeab84743ac8132468b3d6102":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZCEST3y0Ew3","executionInfo":{"status":"ok","timestamp":1669855175519,"user_tz":300,"elapsed":7205,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}},"outputId":"2b5085dc-e1f7-4d17-f215-22c8deef11b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.7/dist-packages (0.3.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from evaluate) (3.1.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from evaluate) (4.64.1)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2.7.1)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.11.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2022.11.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from evaluate) (1.3.5)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.3.6)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from evaluate) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from evaluate) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from evaluate) (4.13.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2.23.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.13.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->evaluate) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->evaluate) (3.10.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->evaluate) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n"]}],"source":["!pip install transformers\n","!pip install evaluate"]},{"cell_type":"code","source":["import csv\n","import torch\n","from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n","\n","topics = []\n","contents = []\n","labels = []\n","\n","with open('/content/drive/MyDrive/ECE1786/project/IEL.csv', newline='') as csvfile:\n","    spamreader = csv.reader(csvfile)\n","    for i, row in enumerate(spamreader):\n","        if i != 0:\n","          topics.append(row[0])\n","          contents.append(row[1])\n","          labels.append(row[2])\n","\n","\n","print(len(topics))\n","print(len(contents))\n","print(len(labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JNZDtLAK0HXg","executionInfo":{"status":"ok","timestamp":1669855176802,"user_tz":300,"elapsed":1287,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}},"outputId":"4f427e5a-17c0-46bc-8fa0-673cbb814a78"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["4004\n","4004\n","4004\n"]}]},{"cell_type":"code","source":["classes = {\n","    '<4': 0,\n","    '4.0': 1,\n","    '4.5': 2,\n","    '5.0': 3,\n","    '5.5': 4,\n","    '6.0': 5,\n","    '6.5': 6,\n","    '7.0': 7,\n","    '7.5': 8,\n","    '8.0': 9,\n","    '8.5': 10,\n","    '9.0': 11\n","}\n","\n","labels2scores = {\n","    '0': 0,\n","    '1': 0.4,\n","    '2': 0.45,\n","    '3': 0.5,\n","    '4': 0.55,\n","    '5': 0.6,\n","    '6': 0.65,\n","    '7': 0.7,\n","    '8': 0.75,\n","    '9': 0.8,\n","    '10': 0.85,\n","    '11': 0.9\n","}\n","\n","from transformers import GPT2Tokenizer\n","\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n","\n","tokenizer.pad_token = tokenizer.eos_token\n","class GPT2Dataset(Dataset):\n","\n","  def __init__(self, topics, contents, labels, tokenizer, max_length=512):\n","\n","    self.tokenizer = tokenizer\n","    self.input_ids = []\n","    self.attn_masks = []\n","    self.labels = []\n","    self.last_idx = []\n","    self.targets = []\n","\n","    for i in range(len(topics)):\n","      input = topics[i].strip() + \" \" + contents[i].strip()\n","      encodings_dict = self.tokenizer(input, truncation=True, max_length=max_length, padding=\"max_length\")\n","      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n","      if labels[i] != \"<4\":\n","        label = classes[str(float(labels[i]))]\n","        self.labels.append(label)\n","        self.targets.append(labels2scores[str(label)])\n","      else:\n","        label = classes[labels[i]]\n","        self.labels.append(label)\n","        self.targets.append(labels2scores[str(label)])\n","      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n","\n","      eot_idx = len(encodings_dict['input_ids']) - 1\n","      for j, id in enumerate(encodings_dict['input_ids']):\n","        if id == self.tokenizer.encode(\"<|endoftext|>\")[0]:\n","          eot_idx = j - 1\n","          break\n","      self.last_idx.append(j-1)\n","      \n","    print(len(self.last_idx))\n","    print(len(self.labels))\n","  def __len__(self):\n","    return len(self.input_ids)\n","\n","  def __getitem__(self, idx):\n","\n","    return self.input_ids[idx], self.attn_masks[idx], self.labels[idx], self.targets[idx], self.last_idx[idx]\n","batch_size = 2\n","dataset = GPT2Dataset(topics, contents, labels, tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kpj6CDQM0JdH","executionInfo":{"status":"ok","timestamp":1669855296229,"user_tz":300,"elapsed":119428,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}},"outputId":"9190a1b9-1bdd-478e-f7cb-306f348f007e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["4004\n","4004\n"]}]},{"cell_type":"code","source":["train_size = int(0.8 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","torch.manual_seed(0)\n","\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","train_dataloader = DataLoader(\n","            train_dataset,\n","            sampler = RandomSampler(train_dataset),\n","            batch_size = batch_size\n","        )\n","\n","validation_dataloader = DataLoader(\n","            val_dataset,\n","            sampler = SequentialSampler(val_dataset),\n","            batch_size = batch_size\n","        )\n","\n","## make sure \n","print(torch.sum(train_dataset[0][0]))\n","\n","print(train_dataset[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kBe2K7vl0icw","executionInfo":{"status":"ok","timestamp":1669855296230,"user_tz":300,"elapsed":23,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}},"outputId":"3887ba33-346f-4366-e740-17846ac77233"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(5779971)\n","(tensor([ 4366,   661,  1975,   326,   645,   530,   815,   307,  3142,   284,\n","         2555,  1762,   706,   262,  2479,   286,  6135,    13,   220,   198,\n","         4864,    11,  1854,   910,   612,  6584,   470,   307,   257, 17385,\n","          319,  2479,   290,  2687,   815,   307,  3142,   284,   670,  7692,\n","          286,   511,  2479,    13,   220,   198, 48873,  1111,  5009,    11,\n","         1577,   534,   898,  4459,   290,  2291,  5981,  6096,    13,  4380,\n","          743,  2328,   326,  2479,   318,   257,  1994,  3210,   284, 22232,\n","         1762, 40460,    13,   220,  6430,   422,   616,  6650,    11,   314,\n","         1975,   326,  2479,   815,   407,   307,   257, 17385,   329,   530,\n","          284,  1620,    13,   201,   198,   201,   198,  2949,  2300,   703,\n","         1468,   262,   661,   389,    11,   484,   991,   460,  8676,  2405,\n","           13,  7129,   815,   407,   307,   262,  2318,   284, 16222,  1586,\n","          262, 13830,  1762, 16826,    13,  1114,  1672,    11,  1011,   262,\n","         4283,  4896,  2214,    11,   262,  4697,   661,   588, 33872,   347,\n","         2001,   316,    11,   508,   318,  1541,  9722,  4101,    11,   991,\n","         1100,  5079,  3136,  4445,   290,  4654,  1123,  2496,  2706,  4495,\n","           13,  1119, 14245,  1975,    11,   706,  1719, 24169,  1998,    11,\n","          511, 42806,   286,   262,  1910,   290,  5370,   389,   517, 15345,\n","          290,  7187,   621,   262,  1862,   661,    13, 23730,    11,   340,\n","          318, 24673,   220,   284,  3958,   220,  4697,   661,   422,  1762,\n","         6974,   780,   286,  2479,   284,  5052,   511,  2854,    13,   201,\n","          198,   201,   198,  2782, 43011,    11,   617,   286,   262,  1762,\n","         4433,  1029,  3518,  3403,   543,   318,   407,  1774,   329,   220,\n","         4697,   661,    13,  1114,  1672,    11,   287,   262,  5701,  2214,\n","           11,  2479,  6870,   530,   872,    88,   271,   605, 17385,   543,\n","         1724,   262,  1767,   338,  3450, 17385,   481, 10070,   511,  4045,\n","         2854,   287,   262,  5449,    13,  4900,    11,   661,  1826,   262,\n","         4096,  2479,   484,  4327,   284,  8058,    11,   220,   484,   991,\n","          481,   220,   307,   257,  3985,   284,  8676,  2405,    13,  7214,\n","        14119,   355,   281,  1672,    11,   257,   582,   460,   991,   307,\n","          257,  3985,   287,  1524,   618,   465,  2479,   318,   625,  6135,\n","           13, 16227,    11,   356,   460,  6189,   220,   766,   326,  2479,\n","         1244,   307,  1611,   286, 17385,   284,   423,   281,  2928,   319,\n","          511,   670,   475,   340,   857,   407,  1265,   606,   284,  6871,\n","         1762,   287,   262,   886,    13,   220,   201,   198,   201,   198,\n","          818,  4506,    11,  2479,   318,   655,   262,  4096,  3210,   284,\n","         8106,   262,   530,   318,  4197,   329,   257,  2176,  2292,   393,\n","          407,   475,   340,   815,   407,   307,   262,  6737,   284,  5052,\n","         1771,   530,   460,   670,   393,   407,    13,  1400,  2300,   287,\n","          262,  4283,  1910,   393,  5701,  2214,    11,   883,  7713,   393,\n","         1938,  3863,   389,  1468,   475,   484,   991,   460,  2222,   511,\n","         1998,   284,   262,  1306,  5270,   287,  3294,  2842,    13, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","        50256, 50256]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0]), 3, 0.5, 418)\n"]}]},{"cell_type":"code","source":["class GPT2_with_regressor(torch.nn.Module):\n","  def __init__(self, embd_size):\n","    super(GPT2_with_regressor, self).__init__()\n","    self.encoder = GPT2Model.from_pretrained(\"gpt2-medium\")\n","    self.regressor = torch.nn.Linear(embd_size, 1)\n","\n","  def forward(self, input, last_idxes):\n","    outputs = self.encoder(**input).last_hidden_state\n","    hidden_states = []\n","    for i in range(len(last_idxes)):\n","      hidden_states.append(outputs[i, last_idxes[i], :][None, :])\n","    hidden_states = torch.cat(hidden_states, dim=0)\n","    outputs = self.regressor(hidden_states)\n","    return outputs\n"],"metadata":{"id":"7jNNWtaIwTNj","executionInfo":{"status":"ok","timestamp":1669855296230,"user_tz":300,"elapsed":19,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from transformers import GPT2Model\n","torch.manual_seed(0)\n","\n","import torch\n","model = GPT2_with_regressor(1024)\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","model.to(device)\n","# regressor.to(device)\n","\n","from torch.optim import AdamW\n","\n","optimizer = AdamW(model.parameters(), lr=1e-5)\n","\n","from transformers import get_scheduler\n","\n","num_epochs = 13\n","num_training_steps = num_epochs * len(train_dataloader)\n","lr_scheduler = get_scheduler(\n","    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",")"],"metadata":{"id":"hvx-2l-O0nrd","executionInfo":{"status":"ok","timestamp":1669855304836,"user_tz":300,"elapsed":8625,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["print(model)"],"metadata":{"id":"NqR7_3_Xwhw0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scores = torch.tensor([0, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9])\n","scores = scores.to(device)"],"metadata":{"id":"_WORlErE8s37","executionInfo":{"status":"ok","timestamp":1669855304837,"user_tz":300,"elapsed":23,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(0)\n","from tqdm.auto import tqdm\n","import evaluate\n","progress_bar = tqdm(range(num_training_steps))\n","\n","model.encoder.config.pad_token_id = tokenizer.pad_token_id\n","\n","mse = torch.nn.MSELoss()\n","train_accs = []\n","val_accs = []\n","for epoch in range(num_epochs):\n","    model.train()\n","    metric = evaluate.load(\"accuracy\")\n","    for input, attn_masks, labels, targets, last_idxes in train_dataloader:\n","        x = {\n","             \"input_ids\": input,\n","             \"attention_mask\": attn_masks,\n","        }\n","        \n","        batch = {k: v.to(device) for k, v in x.items()}\n","        outputs = model(batch, last_idxes)\n","        outputs = torch.special.expit(outputs)\n","        predictions = []\n","        for i in range(len(outputs)):\n","          pred_idx = torch.argmin(abs(scores - outputs[i]))\n","          predictions.append(pred_idx)\n","        predictions = torch.tensor(predictions)\n","        metric.add_batch(predictions=predictions, references=labels)\n","        \n","        # print(outputs, predictions, labels, targets)\n","\n","        targets = targets.to(device)\n","        loss = mse(outputs.float(), targets.float())\n","        loss.backward()\n","        optimizer.step()\n","        lr_scheduler.step()\n","        optimizer.zero_grad()\n","        progress_bar.update(1)\n","        # break\n","    # break\n","    train_acc = metric.compute()['accuracy']\n","    print(train_acc)\n","    # break\n","    train_accs.append(train_acc)\n","    \n","    print(\"Epoch: {}, Train acc: {}\".format(epoch + 1, train_acc))\n","    torch.save(model.state_dict(), \"/content/drive/MyDrive/ECE1786/project/gpt2_regression_{}.pt\".format(epoch))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f4a1129d315d4798883a84333a7ca073","dc7a51b2a0d04e28b9ffab77b5de3cba","837e6994b60a4befaa7305e1aed1a182","c2c45ecf2f664c0689b61472a4229c3a","376ba6fb32584bc082770b51a6a55029","8d08dbcc808e4820aee1eeac5a58ea54","4ea852587e2b43bd96efb88c80adb66f","0a5c88a6018245c59064c210d4cd548e","1277473ba57245c49b598cf7a7c96b91","4385e7702ff547c59fab9b82deb5c34e","453cca8aeab84743ac8132468b3d6102"]},"id":"YkYLT9Hb374G","executionInfo":{"status":"error","timestamp":1669869439523,"user_tz":300,"elapsed":14134707,"user":{"displayName":"Chu Anthony","userId":"01278159702991635327"}},"outputId":"1029e69d-d905-49cc-fabc-28aabeaa02c1"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/20826 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4a1129d315d4798883a84333a7ca073"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["0.09678426475179519\n","Epoch: 1, Train acc: 0.09678426475179519\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["0.12987823915079613\n","Epoch: 2, Train acc: 0.12987823915079613\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["0.12519512956603185\n","Epoch: 3, Train acc: 0.12519512956603185\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["0.13612238526381518\n","Epoch: 4, Train acc: 0.13612238526381518\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["0.14985950671245707\n","Epoch: 5, Train acc: 0.14985950671245707\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["0.14392756790508898\n","Epoch: 6, Train acc: 0.14392756790508898\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["0.14455198251639087\n","Epoch: 7, Train acc: 0.14455198251639087\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["0.14517639712769279\n","Epoch: 8, Train acc: 0.14517639712769279\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["0.14861067748985327\n","Epoch: 9, Train acc: 0.14861067748985327\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["0.14798626287855135\n","Epoch: 10, Train acc: 0.14798626287855135\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-645537788df3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    173\u001b[0m                   \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                   \u001b[0mforeach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'foreach'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                   capturable=group['capturable'])\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    229\u001b[0m          \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m          \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m          capturable=capturable)\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}